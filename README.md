# Toxic Comment Classification
> Multi-label model that’s capable of detecting different types of of toxicity.

## Table of contents
* [General info](#general-info)
* [Technologies](#technologies)
* [Status](#status)
* [Inspiration](#inspiration)
* [Contact](#contact)

## General info
Every online platform which has an open forum faces an issue of people posting inappropriate comments, which if uncontrolled, can lead to loss of users, reputation and revenue. However, it is impractical and expensive for humans to keep track of all the messages other people post. Luckily, ML is here to help. We can train a model to automatically analyze all the messages users write and flag toxic users/comments so that appropriate actions can be taken.

The goal of this project is to build a multi-label model that’s capable of detecting different types of toxicity such as threats, obscenity, insults, and identity-based hate.

## Technologies
Technologies used:
* DistilBERT 
* PyTorch Lightning

## Status
Project is: _finished_

## Inspiration
Project was created using the dataset from [Kaggle Competition](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge)

## Contact
Created by Dovilė Žaltauskaitė [@dovilez] 
